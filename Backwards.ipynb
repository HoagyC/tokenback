{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7nhIKn2YkJ2r","executionInfo":{"status":"ok","timestamp":1673866505511,"user_tz":0,"elapsed":20725,"user":{"displayName":"Jessica Rumbelow","userId":"14021829986331042199"}},"outputId":"1a97ae64-0560-44dd-f5ef-2270a64ce92b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ar1aNn7TxI8r","colab":{"base_uri":"https://localhost:8080/","height":564,"referenced_widgets":["e61a7c095aac47f18bde8251f34b5ac1","5df399ed727049629c02310784a07739","6d3d47869b15430a8b4d294584890e0d","d35425dc791e427d81508b9e830b25ec","901af3867e1f4cc59fa95eab87e5c0f0","b4dc593fb4264268b439605c40d5f1d1","b892cbd7adf544ab81717dc22710e3ba","428301bbbd5e413ea281151257b4c664","7e6e6da84d6d4dbd890a34b320b9480f","5dcb3e193f084912b35fe9371fad77af","c90ad7ab7c0f47ea981da857d5ebeb6a","732a5b2d5f11421290b4ab2821012637","d61fb9738fb343528fd045de685fa0cf","ac191566050f4defabd27612949e70da","20045e7342654adb8542c53191d566a1","fddb87edd610475a853bf74f3e50071e","ec5b70bf6a2f44d1aab44ee73129639c","11cf330f84bb442fbecec383b62cd3a0","6065acb9bbe14f02ba18e7eca039e5f3","1c978f86dc5a491188d4b0002292ec7e","50fa07c7990b477299ad7522e1d69c42","88f098ee31d948dba9f0081b3b99d462","87ab70f75ed34237af93fd0061fefd12","888455fec6bf4c8ea09f411d4cba699f","93ee355564e94696bbb32ac09e49f69a","4d5209794d24493ea55ce4660817418b","1ad2c8dc57ca4fbb99698e0970fc9359","13fd2719c48c4be7bdcc4268838e023d","40f0321e38a240d8bf9cb806fb644e8c","1aa055ee6d2d4fc5ab9098ef994a6470","74962eb3fe7b4781b18c58fd24122330","01d66415c0674f708e1ad170bc72bfaf","0db040840ed44757b37ebc8b0dead8fd","7925e231a35a4b96b87d601c1ebe7c1f","93935b4706024fcea44fa9d960053043","e1888e0200314b7a851030143b432690","0ec3120478284fc9b0ba17f925ca6fda","d7b10343c5c5408499a2ca78414c916e","e32c3fd4d0e943d59d9c13d72a773264","3ae03af8fb694489b15bdef17246d6c0","e89cf8e8508f4810b4df82db58061d46","fb6837190d0241a9a0544a23250d1b81","eb3717f17b694502882607be5d56f5b7","7338745f7720483caf4bb5e76bb9a97e"]},"executionInfo":{"status":"ok","timestamp":1673649553303,"user_tz":0,"elapsed":20683,"user":{"displayName":"Jessica Rumbelow","userId":"14021829986331042199"}},"outputId":"c71a16b8-c58e-4bad-b0ce-bc0d4e750518"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting update\n","  Downloading update-0.0.1-py2.py3-none-any.whl (2.9 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Collecting style==1.1.0\n","  Downloading style-1.1.0-py2.py3-none-any.whl (6.4 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Installing collected packages: style, update\n","Successfully installed style-1.1.0 update-0.0.1\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e61a7c095aac47f18bde8251f34b5ac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"732a5b2d5f11421290b4ab2821012637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87ab70f75ed34237af93fd0061fefd12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7925e231a35a4b96b87d601c1ebe7c1f"}},"metadata":{}}],"source":["!pip install update transformers\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, utils\n","import torch\n","import random\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","from IPython import display\n","import numpy as np\n","from tqdm import tqdm\n","from time import time\n","import json\n","utils.logging.set_verbosity_error()\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","vocab_len= 50257\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", padding_side='left')\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\",pad_token_id=tokenizer.eos_token_id, vocab_size=vocab_len).to(device)\n","model.eval()\n","# the model will be in evaluation, not training, mode throughout\n","word_embeddings = model.transformer.wte.weight.to(device)  \n","embedding_dim = word_embeddings.shape[-1] \n","# 'word_embeddings' tensor gives emeddings for each token in the vocab for this model,\n","# has shape (vocab_len, embedding_dimension) which in this case = (50257, 768)"]},{"cell_type":"code","source":["# code to produce plots of token embeddings\n","\n","from torch.nn.functional import normalize\n","from sklearn.manifold import TSNE\n","\n","# Normalize the tensor\n","tensor = normalize(word_embeddings, p=2, dim=1)\n","\n","# Convert the tensor to a numpy array\n","tensor = tensor.detach().cpu().numpy()\n","\n","# Perform t-SNE\n","tsne = TSNE(n_components=2, random_state=0)\n","reduced_tensor = tsne.fit_transform(tensor)\n","\n","plt.rcParams.update({'figure.figsize': (100,100)})\n","\n","# Plot the reduced tensor\n","plt.scatter(reduced_tensor[:, 0], reduced_tensor[:, 1], marker='.', color='white')\n","\n","# Annotate each point with its index\n","for i, point in enumerate(np.random.permutation(reduced_tensor)[:5026]):\n","    try:\n","        if '$' not in repr(tokenizer.decode(i)):\n","            plt.annotate(repr(tokenizer.decode(i)), (point[0], point[1]), fontsize=15, xytext=(0, 0), textcoords='offset points')\n","    except:\n","        pass\n","plt.show()\n"],"metadata":{"id":"bhBGswIlR2Jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# more code to produce plots of token embeddings\n","\n","plt.rcParams.update({'figure.figsize': (100,100)})\n","\n","# Plot the reduced tensor\n","plt.scatter(reduced_tensor[:, 0], reduced_tensor[:, 1], marker='.', color='white')\n","\n","# Annotate each point with its index\n","for i, point in enumerate(np.random.permutation(reduced_tensor)[:5026]):\n","    try:\n","        if '$' not in repr(tokenizer.decode(i)):\n","            plt.annotate(repr(tokenizer.decode(i)), (point[0], point[1]), fontsize=15, xytext=(0, 0), textcoords='offset points')\n","    except:\n","        pass\n","plt.show()"],"metadata":{"id":"kgeEwu2AUlcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalise(x, min_max=[]):     \n","# normalises values of (array or tensor) x according to first (min) and second (max) values in list min_max. \n","# This effectively defaults to [0,1] if the list doesn't contain exactly two elements. \n","# Note that list can contain an array (which is what happens when it's called to define 'start_input').\n","\n","# First normalise x values to [0,1]\n","    rnge = x.max() - x.min()\n","    if rnge > 0:\n","        x = (x - x.min())/rnge\n","# Now, if there's a min and max given in min_max list, multiply x values by (max - ) and add minimum.\n","    if len(min_max) > 1:\n","        rnge = min_max[1] - min_max[0]\n","        x = x * rnge + min_max[0]\n","\n","    return x\n","\n","\n","def closest_tokens(emb, n=1):      \n","# This finds the n tokens in the vocabulary that are closest in the embedding space (in terms of Euclidean distance) to a given word embedding (‘emb’).\n","# Note that here 'emb' may or may not correspond to a token (i.e., it may or may not be a 'legal' embedding).\n","# Function returns a 4-tuple (list of the n tokens, list of their indices, list of their distances from emb, and list of their embedding vectors)\n","    torch.cuda.empty_cache()\n","    dists = torch.linalg.norm(word_embeddings - emb, dim=1)\n","    sorted_dists, ix = torch.sort(dists)\t \n","    # sorted_dists is a list of all embedding distances from 'emb', across entire vocab, sorted in increasing order, \n","    # ix is a list of their corresponding 'vocab indices'\n","    tokens = [tokenizer.decode(i) for i in ix[:n]]\n","    # For each of the first n 'vocab indices' in ix, we decode it into the string version of the corresponding token. \n","    # These strings then constitute the list 'tokens'.\n","    ixs = ix[:n]\n","    dists = sorted_dists[:n]\n","    embs = word_embeddings[ixs]  # Each of these n 'embeddings' is a tensor of shape (768,)\n","    return tokens, ixs, dists, embs  \n","\n","\n","def model_emb(inputs_embeds, output_len):\n","# 'input_embeds' is a tensor of shape (batch_size, input_len, embedding_dim)\n","# 'output_len' is an integer specifying the number of output tokens to generate\n","# Note that this function doesn't involve a target output. It simply takes a tensor of input embeddings (based on input length),\n","# calculates perplexities for that batch of input sequences, and runs the batch of input sequences through GPT2, \n","# for each finding next tokens iteratively 'output_len' number of times.\n","    embs = inputs_embeds   # This is going to get expanded using 'output_embs'\n","    logits = []\n","    ixs = []\n","    input_logits = None\n","    for i in range(output_len):\n","        model_out = model(inputs_embeds=embs, return_dict=True)\n","        # Does a forward pass of GPT2 (or whichever model) on a batch of inputs (given as a tensor 'embs' of embeddings).\n","        # This 'embs' will expand along its 1st dimension with each iteration.\n","        # It outputs logits and more (hidden states, attention, etc.) as a dictionary 'model_out',\n","        # but we'll only be concerned with model_out.logits.\n","\n","        if i == 0:\n","            input_logits = model_out.logits \n","            # On first pass through loop, we simply use the logits of the model output.\n","            # That's a tensor of shape (batch_size, input_len, vocab_size) giving logits for each input in each batch.\n","            # Presumably for each input, this is conditioned on the inputs that preceded it?\n","\n","        # On every pass throught the loop (including the first), we defined this tensor of shape (batch_size, 1, vocab_size):\n","        last_logits = model_out.logits[:,-1].unsqueeze(1)  \n","        # model_out.logits[:,-1] will be a 2D tensor of shape (batch_size, vocab_size), just giving logits for last input/embedding across all batches/tokens.\n","        # Unsqueezing, we get tensor of shape (batch_size, 1, vocab_size), also giving logits of last input/embedding, but differently formatted.  \n","        logits.append(last_logits)  # appends last_logits tensor to the 'logits' list \n","        ix = torch.argmax(last_logits, dim=-1)  # for each batch, finds the vocab index of the token with the largest logit in last_logits\n","        ixs.append(ix) # ...and appends this tensor of shape (batch_size,) (containing indices) to the list 'ixs'\n","        output_embs = word_embeddings[ix]   # for each batch, finds embedding for the token with that index...\n","        embs = torch.cat([embs, output_embs], dim=1)  #... and concatenates that tensor of embeddings to the 'embs' tensor in the first dimension, before next iteration.\n","\n","     # When the loop is completed 'embs' will be a tensor containing all of the input and output word embeddings produced by the model,   \n","     # of shape (batch_size, input_len + output_len, embedding_dim)\n","\n","    logits = torch.cat(logits, dim=1)   # this converts logits from a list of tensors to a single tensor, by concatenating all of the tensors in the list\n","                                        # it will have shape (batch_size, output_len, vocab_size)\n","    perp = perplexity(input_logits)     # 'input_logits' was calculated on first pass through loop where only input embeddings were involved\n","    return logits, embs, perp          \n","    # logits has shape (batch_size, output_len, vocab_size),     \n","    # embs has shape (batch_size, input_len + output_len, embedding_dim),\n","    # perp has shape (batch_size,)\n","\n","\n","def perplexity(logits):\n","    # logits is of shape (batch_size, 'sequence length', vocab_size)\n","    # for all current calls, 'sequence length' is going to be input_len\n","    probs, ix = torch.max(torch.softmax(logits, dim=-1), dim=-1)\n","    # torch.softmax(logits, dim=-1) will also be a tensor of shape (batch_size, 'sequence length', vocab_size), \n","    # but where we convert the logits in the last dimension into probabilities via softmax.torch.max() and then pull out the largest of these and its index\n","    # probs is a tensor that contains the maximum probability for each token in the embedding sequence, shape (batch_size, 'sequence length')\n","    # ix is a tensor that contains the corresponding indices, also with shape (batch_size, 'sequence length')\n","    perp = 1/ (torch.prod(probs, dim=-1)**(1/probs.shape[-1])) - 1\n","    # defines a scalar that's larger with greater uncertainty (so if the probs are small, their product is small, the reciprocal of some power is large)\n","    # probs.shape[-1] is output_len; the idea of raising the probs product to power 1/output_len is to make perplexities comparable across different output lengths\n","    return perp\n","\n","\n","# The key function that optimises for a sequence of input embeddings, given a target_output string:\n","def optimise_input(epochs=100, \n","                   lr=0.1, \n","                   rand_after=False,    # Do we re-initialise inputs tensor with random entries when an optimal input is found?\n","                   w_freq=10,           # logging (write) frequency\n","                   base_input=None,      # If none, start_inputs will be entirely random; \n","                                         # otherwise it will be built by stacking this tensor and then gently \"noising\" all but the first copies\n","                   batch_size=1, \n","                   input_len=1, \n","                   target_output=tokenizer.eos_token,    # Default target output is the \"end-of-string\" token; this won't generally be used\n","                   output_len=None,\n","                   dist_reg=1,       # distance regularisation coefficient\n","                   perp_reg=0,       # perplexity regularisation coefficient; setting to 0 means perplexity loss isn't a thing\n","                   plt_loss=False,   # Do we plot loss?\n","                   loss_type='log_prob_loss', \n","                   seed=0,\n","                   return_early=True,    # finishes if single optimised input is found\n","                   verbose=0,            # Controls how much info gets logged.\n","                   lr_decay=False,       # Use learning rate decay? If so, a scheduler gets invoked.\n","                   noise_coeff = 0.01):     # Introduced for generality in the construction of start_input[1:] below.\n","    torch.manual_seed(seed)               # sets up PyTorch random number generator\n","\n","    if plt_loss:\n","        plt.rcParams.update({'figure.figsize': (40,6)})\n","\n","    total_losses = []\n","    losses = []\n","    dists = []\n","    perps = []\n","    optimised_inputs = set()\n","    done = None\n","\n","    output_ix = tokenizer.encode(target_output, return_tensors='pt')[0].to(device)\n","    # output_ix is a 1-D tensor of shape (output_len,) that contains the indices of the tokens in the encoding of the string 'target_output'\n","    # tokenizer.encode(target_output, return_tensors='pt') is a list containing this one tensor, hence the need for the [0]\n","    # \"return_tensors='pt'\" ensures that we get a tensor in PyTorch format\n","\n","    if output_len == None or output_len < output_ix.shape[0]:    # This won't generally be the case, but if we don't specify output_len (i.e. it's == None), then...\n","        output_len = output_ix.shape[0]       # ...it will be set to the number of tokens in the encoding of the string 'target_output'\n","\n","    print('Optimising input of length {} to maximise output logits for \"{}\"'.format(input_len, target_output))\n","    # Typically this would print something like 'Optimising input of length 6 to maximise output logits for \"KILL ALL HUMANS!\"'.\n","\n","    if base_input == None:\n","        start_input = torch.rand(batch_size, input_len, word_embeddings.shape[-1]).to(device)\n","        # If no base_input is provided, we construct start_input as a random tensor... \n","        # ...of shape (batch_size, input_len, embedding_dim) (embedding_dim = 768 for this GPT-2 model).\n","        start_input = normalise(start_input,[word_embeddings.min(dim=0)[0], word_embeddings.max(dim=0)[0]])\n","        # We normalise this random tensor so that its minimum and maximum values correspond to those in the entire word_embeddings tensor\n","        # This dispenses with whole swathes of \"input space\" which contain no legal token embeddings \n","        # (we're limiting ourselves to a kind of \"hull\" defined by the vocab tokens in the embedding space), \n","        # which is a sensible place to look for optimised inputs.\n","    else:\n","        start_input = base_input.repeat(batch_size, 1, 1)\n","        # If a base_input was given, it should be of shape (input_len, embedding_dim), \n","        # and we build the start_input tensor by stacking 'batch_size' number of copies of this together...\n","\n","        if batch_size > 1:\n","            start_input[1:] += (torch.rand_like(start_input[1:]) + torch.full_like(start_input[1:], -0.5)) * noise_coeff\n","        # ...and if we have more than one element in our batch, we \"noise\" the rest. \n","        # This was originally done using \"*=\" (multiplying entries by small random numbers)\n","    \n","    input = torch.nn.Parameter(start_input, requires_grad=True)\n","    # input is not a tensor, it's a Parameter object that wraps a tensor and adds additional functionality. \n","    # 'input.data' is used below\n","    \n","    optimiser = torch.optim.Adam([input], lr=lr)\n","    # standard optimiser; note that it generally operates on a list of tensors, so we're giving it a list of one tensor; standard learning rate\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min', patience=20, cooldown=20, factor=0.5)\n","    # this is used when loss hasn't improved for 20 timesteps; this scheduler will reduce the lr by a 'factor' of 0.5 when the \n","    # validation loss stops improving for 'patience' (here 20) epochs, and will wait 'cooldown' (here 20) epochs before resuming normal operation.\n","\n","    # now loop across training epochs\n","    for e in range(epochs):\n","\n","        logits, emb, perp = model_emb(torch.clamp(input, word_embeddings.min(), word_embeddings.max()), output_len)\n","        # Does forward pass on a 'clamped' version of the 'input' tensor (done to contain it within the 'hull' of the vocabulary within embedding space).\n","        # Iterates to produce an output of output_len tokens, returns:\n","        # 'logits' = tensor of logits for output, of shape (batch_size, output_len, vocab_size)\n","        # 'emb': tensor of embeddings for input+output, of shape (batch_size, input_len + output_len, embedding_dim); \n","        # 'perp': the input sequence perplexities tensor, of shape (batch_size,)\n","        probs = torch.softmax(logits, dim=-1)\n","        # For each batch, output, converts the sequence of logits (of length 'vocab_size') in the 'logits' tensor to probabilities, using softmax.\n","\n","        logits = (logits - logits.min(dim=-1)[0].unsqueeze(-1)) / (logits.max(dim=-1)[0].unsqueeze(-1) - logits.min(dim=-1)[0].unsqueeze(-1))\n","        # This appears to be normalising the logits for each batch/output embedding so they're all between 0 and 1. \n","        # This is for ease of visualisation.\n","\n","        perp_loss = perp.mean() * perp_reg\n","        # That's taking the mean perp value across all batches, then regularising it.\n","\n","        if output_len > output_ix.shape[0]:\n","            target_logits = torch.stack([logits[:, :, ix] for ix in output_ix], dim=-1)\n","            target_logits = torch.max(target_logits, dim=-1)[0]\n","            # logits has shape (batch_size, output_len, vocab_size) \n","            # We throw out everything in the final dimension except those logits corresponding to indices of tokens in the target_ouput\n","            # This gives tensor with shape (batch_size, output_len, output_ix.shape[0])\n","            # We then take the maximum of those logits for each batch, output; this gives shape (batch_size, output_len)\n","            # The [0] returns just the maximum (torch.max returns max, indices tuple).\n","            target_probs = torch.stack([probs[:, :, ix] for ix in output_ix], dim=-1)\n","            target_probs = torch.max(target_probs, dim=-1)[0]\n","            # This does the analogous thing for probs.\n","\n","        else:\n","            target_logits = torch.stack([logits[:,i, ix] for i, ix in enumerate(output_ix)], dim=-1)\n","            target_probs = torch.stack([probs[:,i, ix] for i, ix in enumerate(output_ix)], dim=-1)\n","            # This handles case where output_len == output_ix.shape[0]\n","            # target_logits isnow of shape (batch_size, output_len)\n","            # output_len < output_ix.shape[0] was dealt with in line 133\n","            \n","        token_dist = torch.stack([torch.stack([closest_tokens(e)[2].squeeze(-1) for e in input[b]]) for b in range(batch_size)])\n","        # As far as I can tell, this creates a tensor of shape (batch_size, input_len, 1) which gives distance to nearest\n","        # legal token embedding for each input embedding in each batch\n","        mean_token_dist = token_dist.mean() * dist_reg\n","        # A single scalar value, taking mean across the batch and input embeddings? \n","\n","\n","        # There are currently four loss types, many more could be introduced.\n","        # log_prob_loss is the current default.\n","        if loss_type == 'logit_loss':\n","            loss = torch.mean(1-target_logits)\n","        elif loss_type == 'log_prob_loss':\n","            loss = -torch.log(target_probs).mean()\n","        elif loss_type == 'prob_loss':\n","            loss = 1-torch.mean(target_probs)\n","        elif loss_type == 'CE':\n","            loss = torch.nn.functional.cross_entropy(logits.swapaxes(-1,-2), output_ix.repeat(batch_size, 1))\n","\n","        else:\n","            print(loss_type + 'is not implemented.')\n","            return\n","\n","        total_loss = torch.stack([mean_token_dist, loss, perp_loss]).mean()\n","        # This is this just (mean_token_dist + loss + perp_loss)/3 tensorised across batches, yes?\n","\n","        total_losses.append(total_loss.detach().cpu().data)\n","        losses.append(loss.detach().cpu().data)\n","        dists.append(mean_token_dist.detach().cpu().data)\n","        perps.append(perp_loss.detach().cpu().data)\n","        # these four lists were intialised above. We're appeneding to the list each epoch. All are scalars.\n","\n","        closest_ix = torch.stack([torch.stack([closest_tokens(e)[1] for e in b]) for b in input]).squeeze(-1)\n","        # This is similar to above, but building a tensor of indices of nearest embeddings, rather than distances.\n","        # Iterates over batches, and for each batch iterates over embeddings, giving tensor of shape (batch_size, input_len).\n","\n","        model_outs = model.generate(closest_ix, max_length = output_len+input_len)\n","        # The 'closest_ix' tensor is passed as the initial input sequence to the model, \n","        # and the max_length parameter specifies the maximum length of the total sequence to generate.\n","        # The output sequence will be terminated either when the end-of-sequence token is generated \n","        # or when the maximum length is reached, whichever occurs first.\n","        # \n","        # The output of the model.generate method will be a tuple containing the generated sequences and the model's internal states. \n","        # The generated sequences will be stored in a tensor of shape (batch_size, output_len+input_len). \n","        # Each element of the tensor will be a sequence of vocab indices with a length of at most output_len+input_len.\n","        \n","        for b in range(batch_size):\n","        # iterate over batches  \n","            if output_len > output_ix.shape[0]:\n","                if target_output in tokenizer.decode(model_outs[b][input_len:]):\n","                    done = tokenizer.decode(model_outs[b][:input_len])\n","                    optimised_inputs.add(done)\n","                # model_outs[b][input_len:], for a batch b, is only looking at the *output* embeddings \n","                # we decode these as tokens... is the target_output a substring?\n","                # if so, we print the target_output and the decoded string that contains it\n","                # 'done' is the string version of the model's output for given input, we add this to set 'optimised_inputs'.\n","\n","                if rand_after:\n","                    input.data[b] = torch.rand_like(input[b])\n","                    # This will require new normalisation function.\n","                    # The idea here seems to be randomly re-initialise the input tensor once we've found an optimised input,\n","                    # input.data is the tensor version of the 'input' Parameter object. Current values, without gradient!\n","                    # That's of shape (batch_size, input_len, embedding_dim)\n","\n","            if tokenizer.decode(model_outs[b][input_len:]) == target_output:\n","                done = tokenizer.decode(model_outs[b][:input_len])\n","                optimised_inputs.add(done)\n","                # model_outs[b][input_len:], for a batch b, is only looking at the *output* embeddings \n","                # we decode these as tokens... is the target_output equal to output string?\n","                # Nothing printed in this case.\n","                # 'done' is the string version of the model's output for given input, we add this to set 'optimised_inputs'.\n","                if rand_after:\n","                    input.data[b] = torch.rand_like(input[b])\n","                    # Random re-initialisation (if 'rand_after' set to True)\n","\n","  \n","        if ((e+1) % w_freq == 0) or done and return_early:\n","            display.clear_output(wait=True)  \n","        # Every w epochs we write to log, unless we have found an optimised input before that and 'return_early' == True. \n","        # I'm still not entirely sure about the idea of 'return_early'.\n","\n","            if plt_loss:\n","                plt.plot(range(len(total_losses)), total_losses, label='Total Loss', color='black')\n","                plt.plot(range(len(losses)), losses, label='Output Loss')\n","                plt.plot(range(len(dists)), dists, label='Emb Dist Loss')\n","                plt.plot(range(len(perps)), perps, label='Perp Loss')\n","                plt.yscale('log')\n","                plt.legend()\n","\n","                plt.show()\n","\n","            print('Inputs found: ', optimised_inputs)\n","            print('{}/{} Output Loss: {} Emb Dist Loss: {} Perp Loss: {} LR: {}'.format(e+1, epochs, loss, mean_token_dist, perp_loss, optimiser.param_groups[0]['lr']))\n","            if verbose == 3:\n","                print('Target Probs: {}\\nTarget Logits: {}\\nInput Dists: {}\\nInput Perplexity: {}\\n'.format(target_probs.detach().cpu().numpy(), target_logits.detach().cpu().numpy(), token_dist.detach().cpu().numpy(), perp.detach().reshape(-1).cpu().numpy()))\n","            # Optimised inputs and additional information are printed as part of log\n","\n","            for b in range(batch_size):\n","                if verbose > 0:\n","                    if verbose == 2:\n","                        print(b, repr(' Raw embeddings: {}'.format(''.join([closest_tokens(e)[0][0] for e in emb[b]]))))\n","                        # Change name to clarify?\n","                        # Input embeddings get pushed though model to produce output tokens...\n","                        # ...then input embeddings get snapped to nearest tokens...\n","                        # ...then all these 'input' and output tokens get concatenated and printed\n","                        # closest_tokens(e)[0] is a list of tokens, closest_tokens(e)[0][0] is the first (closest) of these\n","                        # these get joined with separator '' (most tokens come with a leading blank space)\n","                    print(b, repr(' Closest embeddings: {}'.format(tokenizer.decode(model_outs[b]), '\\n')))\n","                        # Change name to clarify?\n","                        # Here the input embeddings have already been snapped to the nearest tokens, THEN pushed though the model\n","                        # Therefore the first input_len tokens in 'Raw embeddings' and 'Closest embeddings' will be the same...\n","                        # ...but the remaining output_len tokens may well differ.\n","                else:\n","                    print(repr(tokenizer.decode(model_outs[b])), end=' ')\n","                    # The least verbose printed output. The 'end' parameter is used to specify the end-of-line string that is appended to the output. \n","                    # By default, this is a newline character, but in this case it has been set to a single space character, \n","                    # so the output will be separated by spaces rather than newlines.\n","\n","            if done and return_early:\n","                print('\\nOptimised Input: \"{}\"'.format(done))\n","                return optimised_inputs\n","                # we know optimised_inputs set contains a single element in this case\n","            \n","        optimiser.zero_grad()\n","        total_loss.backward()\n","        optimiser.step()\n","        # I assume these three lines are standard NN optimisation stuff?\n","\n","        if lr_decay:\n","            scheduler.step(total_loss)\n","         # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min', patience=20, cooldown=20, factor=0.5) gets used if lr_decay == True\n","    \n","    return optimised_inputs\n","    # that's a set of strings\n"],"metadata":{"id":"iXOb1alFkA-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# attempt to implement k-means algorithm\n","\n","def kmeans(num_clusters):\n","\n","    empty_cluster = True\n","\n","    # euclidean distance threshold to break out of loop\n","    threshold = 0\n","\n","    while empty_cluster == True: \n","        # randomly generate num_clusters centroids, stack these into a tensor of shape (num_clusters, 768)\n","        # then normalise to vocab embedding span\n","        centroids = torch.rand(num_clusters, embedding_dim).to(device)\n","        centroids = normalise(centroids,[word_embeddings.min(dim=0)[0], word_embeddings.max(dim=0)[0]])\n","\n","        distances = torch.cdist(word_embeddings, centroids, p=2)\n","        # This will be of shape (vocab_len, num_clusters), recording distances of all token embeddings from each of the centroid.\n","        closest_distance, closest_centroid = torch.min(distances, dim = -1)\n","        # These will be of shape (vocab_len,), recording the distance of each token embedding to nearest centroid, and the index of that centroid.\n","\n","        clusters = []\n","        mean_distances = []\n","        # We iterate over the centroids:\n","        for i in range(num_clusters):\n","            mask = closest_centroid == i  # This builds a Boolean mask over the complete set of tokens, True if a token's nearest centroid is the ith.\n","            clusters.append(word_embeddings[mask]) \n","            # word_embeddings[mask] is a subtensor of the (50257, 768) shape tensor involving only tokens nearest ith centroid.\n","            # This subtensor gets appended to the list 'clusters', which will end up with num_clusters elements.\n","\n","        cluster_sizes = [clusters[i].shape[0] for i in range(num_clusters)]  \n","        if 0 not in cluster_sizes:\n","            empty_cluster = False   # We break out of our loop when none of the clusters have size zero\n","                                    # So every centroid must now be the closest of the centroids to at least one token embedding.\n","\n","    # Now we have a set on num_clusters non-empty clusters, we begin iterating centroid positions:\n","    centroids_stable = False\n","    iterations = 0\n","\n","    while centroids_stable == False:\n","        iterations += 1\n","        distances = torch.cdist(word_embeddings, centroids, p=2)\n","        # This will be of shape (vocab_len, num_clusters), recording distances of token embeddings from each of the centroid.\n","        closest_distance, closest_centroid = torch.min(distances, dim = -1)\n","        # These will be of shape (vocab_len,), recording the distance of each token embedding to nearest centroid, and the index of that centroid.\n","\n","        clusters = []\n","        mean_distances = []\n","        # We iterate over the centroids, building centroid-wise lists of clusters and mean distances \n","        for i in range(num_clusters):\n","            mask = closest_centroid == i  # This builds a Boolean mask over the complete set of tokens, True if a token's nearest centroid is the ith.\n","            clusters.append(word_embeddings[mask]) \n","            # word_embeddings[mask] is a subtensor of the shape (50257, 768) word_embeddings tensor involving only tokens nearest ith centroid.\n","            # This subtensor gets appended to the list 'clusters' (num_clusters elements).\n","            mean_distances.append(closest_distance[mask].mean().item()) \n","            # closest_distance[mask] is a subtensor of the (50257,) shape tensor involving only tokens nearest ith centroid...\n","            # ... and closest_distance[mask].mean() is mean distance of those tokens from ith centroid\n","            # This value gets appended to the list 'mean_distances' (num_clusters elements).\n","\n","        new_centroids = []\n","        for i in range(num_clusters):\n","            new_centroids.append(clusters[i].mean(dim=0))\n","            # clusters[i].mean(dim=0) is the centroid of the set of vectors encoded in the shape (,768) tensor clusters[i] \n","            # these all get put into the list new_centroids\n","\n","        new_centroids = torch.stack(new_centroids)\n","        # ... and the list gets stacked into a tensor of shape (num_clusters, 768)\n","\n","        # We now compute the euclidean distance between old and new centroids\n","        distance = torch.norm(new_centroids - centroids, dim=-1)\n","        print('iteration: ', iterations, '\\n max distance between old and new centroids:', torch.max(distance).item())\n","\n","        if torch.max(distance) <= threshold:\n","            centroids_stable == True\n","            break   # centroids have stabilised, so we break out of the loop\n","        centroids = new_centroids # otherwise we're still outside the distance threshold, so keep iterating\n","    \n"," \n","    for i in range(len(clusters)):\n","        print('Cluster', i, ' contains ', len(clusters[i]), ' embeddings.')\n","        print('Cluster', i, 'has centroid ', centroids[i][range(8)], '...')\n","    for j in range(num_clusters):\n","        # sanity check this by finding the embedding in the cluster nearest the centorid\n","        cluster = clusters[j]\n","        centroid = centroids[j].unsqueeze(0) # adding a dimension\n","        # tensor of distances from all token embeddings in clusters[j] to embedding centroids[j]\n","        cluster_distances = torch.norm(cluster - centroid, dim=1)\n","\n","        min_distance, min_index = torch.min(cluster_distances, dim=0)            \n","        print('Smallest distance from centroid', j, 'to a token embedding in cluster', j, '= ', min_distance.item())\n","        print('The relevant token is ', closest_tokens(clusters[j][min_index])[0])\n","        print('Its embedding starts ', clusters[j][min_index][range(8)], '...')\n","        print('Closest token from entire vocab to centroid', j,':', closest_tokens(centroids[j])[0],', vocab index', closest_tokens(centroids[j])[1].item())\n","        print('Distance from centroid', j, 'to this closest token =', torch.norm(word_embeddings[closest_tokens(centroids[j])[1].item()] - centroid))\n","        print('\\n')\n","    print('Distance from externalToEVA to centroids = ', [torch.norm(word_embeddings[30212] - centroids[j]).item() for j in range(25)])\n","    return centroids"],"metadata":{"id":"2jZJMakszJ_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kmeans(25)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_Mn0fY3FF8s","executionInfo":{"status":"ok","timestamp":1673620727120,"user_tz":0,"elapsed":2301,"user":{"displayName":"The Inamorata Press","userId":"11358823481707850507"}},"outputId":"0121b8aa-ca2b-43ab-854a-f621ad49d773"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["iteration:  1 \n"," max distance between old and new centroids: 9.38183879852295\n","iteration:  2 \n"," max distance between old and new centroids: 0.857846736907959\n","iteration:  3 \n"," max distance between old and new centroids: 0.9770517349243164\n","iteration:  4 \n"," max distance between old and new centroids: 0.6848060488700867\n","iteration:  5 \n"," max distance between old and new centroids: 0.4010399281978607\n","iteration:  6 \n"," max distance between old and new centroids: 0.25260230898857117\n","iteration:  7 \n"," max distance between old and new centroids: 0.26106947660446167\n","iteration:  8 \n"," max distance between old and new centroids: 0.3878091275691986\n","iteration:  9 \n"," max distance between old and new centroids: 0.5297049880027771\n","iteration:  10 \n"," max distance between old and new centroids: 0.27062681317329407\n","iteration:  11 \n"," max distance between old and new centroids: 0.13183221220970154\n","iteration:  12 \n"," max distance between old and new centroids: 0.08200440555810928\n","iteration:  13 \n"," max distance between old and new centroids: 0.0720934271812439\n","iteration:  14 \n"," max distance between old and new centroids: 0.06797510385513306\n","iteration:  15 \n"," max distance between old and new centroids: 0.06388335675001144\n","iteration:  16 \n"," max distance between old and new centroids: 0.07392837852239609\n","iteration:  17 \n"," max distance between old and new centroids: 0.07371985167264938\n","iteration:  18 \n"," max distance between old and new centroids: 0.08236128091812134\n","iteration:  19 \n"," max distance between old and new centroids: 0.07867758721113205\n","iteration:  20 \n"," max distance between old and new centroids: 0.06799204647541046\n","iteration:  21 \n"," max distance between old and new centroids: 0.051334887742996216\n","iteration:  22 \n"," max distance between old and new centroids: 0.054453253746032715\n","iteration:  23 \n"," max distance between old and new centroids: 0.05437444522976875\n","iteration:  24 \n"," max distance between old and new centroids: 0.05474960431456566\n","iteration:  25 \n"," max distance between old and new centroids: 0.05334009602665901\n","iteration:  26 \n"," max distance between old and new centroids: 0.05525181069970131\n","iteration:  27 \n"," max distance between old and new centroids: 0.054207682609558105\n","iteration:  28 \n"," max distance between old and new centroids: 0.05303129553794861\n","iteration:  29 \n"," max distance between old and new centroids: 0.041113339364528656\n","iteration:  30 \n"," max distance between old and new centroids: 0.035209544003009796\n","iteration:  31 \n"," max distance between old and new centroids: 0.043048273772001266\n","iteration:  32 \n"," max distance between old and new centroids: 0.05220528692007065\n","iteration:  33 \n"," max distance between old and new centroids: 0.05516112223267555\n","iteration:  34 \n"," max distance between old and new centroids: 0.06000087782740593\n","iteration:  35 \n"," max distance between old and new centroids: 0.07613294571638107\n","iteration:  36 \n"," max distance between old and new centroids: 0.09883414208889008\n","iteration:  37 \n"," max distance between old and new centroids: 0.11233724653720856\n","iteration:  38 \n"," max distance between old and new centroids: 0.10888206213712692\n","iteration:  39 \n"," max distance between old and new centroids: 0.08836060762405396\n","iteration:  40 \n"," max distance between old and new centroids: 0.06482090801000595\n","iteration:  41 \n"," max distance between old and new centroids: 0.051049672067165375\n","iteration:  42 \n"," max distance between old and new centroids: 0.0687880665063858\n","iteration:  43 \n"," max distance between old and new centroids: 0.05472859740257263\n","iteration:  44 \n"," max distance between old and new centroids: 0.04103797674179077\n","iteration:  45 \n"," max distance between old and new centroids: 0.03454867750406265\n","iteration:  46 \n"," max distance between old and new centroids: 0.030776266008615494\n","iteration:  47 \n"," max distance between old and new centroids: 0.03139204904437065\n","iteration:  48 \n"," max distance between old and new centroids: 0.03197362273931503\n","iteration:  49 \n"," max distance between old and new centroids: 0.028570737689733505\n","iteration:  50 \n"," max distance between old and new centroids: 0.025667957961559296\n","iteration:  51 \n"," max distance between old and new centroids: 0.018395069986581802\n","iteration:  52 \n"," max distance between old and new centroids: 0.014249734580516815\n","iteration:  53 \n"," max distance between old and new centroids: 0.01271392498165369\n","iteration:  54 \n"," max distance between old and new centroids: 0.009371940977871418\n","iteration:  55 \n"," max distance between old and new centroids: 0.007117601577192545\n","iteration:  56 \n"," max distance between old and new centroids: 0.008009777404367924\n","iteration:  57 \n"," max distance between old and new centroids: 0.009857084602117538\n","iteration:  58 \n"," max distance between old and new centroids: 0.009368358179926872\n","iteration:  59 \n"," max distance between old and new centroids: 0.008995465002954006\n","iteration:  60 \n"," max distance between old and new centroids: 0.008458712138235569\n","iteration:  61 \n"," max distance between old and new centroids: 0.008592688478529453\n","iteration:  62 \n"," max distance between old and new centroids: 0.008838820271193981\n","iteration:  63 \n"," max distance between old and new centroids: 0.007231390103697777\n","iteration:  64 \n"," max distance between old and new centroids: 0.00705812918022275\n","iteration:  65 \n"," max distance between old and new centroids: 0.0052767349407076836\n","iteration:  66 \n"," max distance between old and new centroids: 0.003957817330956459\n","iteration:  67 \n"," max distance between old and new centroids: 0.003972391597926617\n","iteration:  68 \n"," max distance between old and new centroids: 0.004380814265459776\n","iteration:  69 \n"," max distance between old and new centroids: 0.0038813201244920492\n","iteration:  70 \n"," max distance between old and new centroids: 0.0041594128124415874\n","iteration:  71 \n"," max distance between old and new centroids: 0.004145660437643528\n","iteration:  72 \n"," max distance between old and new centroids: 0.003798746271058917\n","iteration:  73 \n"," max distance between old and new centroids: 0.00214833184145391\n","iteration:  74 \n"," max distance between old and new centroids: 0.0031593437306582928\n","iteration:  75 \n"," max distance between old and new centroids: 0.004052611533552408\n","iteration:  76 \n"," max distance between old and new centroids: 0.005130664445459843\n","iteration:  77 \n"," max distance between old and new centroids: 0.004384589847177267\n","iteration:  78 \n"," max distance between old and new centroids: 0.0034626934211701155\n","iteration:  79 \n"," max distance between old and new centroids: 0.0047660404816269875\n","iteration:  80 \n"," max distance between old and new centroids: 0.004546922631561756\n","iteration:  81 \n"," max distance between old and new centroids: 0.004338495433330536\n","iteration:  82 \n"," max distance between old and new centroids: 0.004761538002640009\n","iteration:  83 \n"," max distance between old and new centroids: 0.005913719069212675\n","iteration:  84 \n"," max distance between old and new centroids: 0.0026185880415141582\n","iteration:  85 \n"," max distance between old and new centroids: 0.002486658748239279\n","iteration:  86 \n"," max distance between old and new centroids: 0.0022575450129806995\n","iteration:  87 \n"," max distance between old and new centroids: 0.0023190455976873636\n","iteration:  88 \n"," max distance between old and new centroids: 0.0030396333895623684\n","iteration:  89 \n"," max distance between old and new centroids: 0.0\n","Cluster 0  contains  2699  embeddings.\n","Cluster 0 has centroid  tensor([-0.0271, -0.0444,  0.1192, -0.0066,  0.0200,  0.0511, -0.3599, -0.0079],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 1  contains  2195  embeddings.\n","Cluster 1 has centroid  tensor([-0.0097, -0.0867,  0.2000, -0.0162, -0.0053, -0.0345, -0.2324, -0.0685],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 2  contains  4231  embeddings.\n","Cluster 2 has centroid  tensor([ 0.0087, -0.0629,  0.1017, -0.0434, -0.0271,  0.0181, -0.3612, -0.1011],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 3  contains  5  embeddings.\n","Cluster 3 has centroid  tensor([-0.0936, -0.0627,  0.1936,  0.0129, -0.0331,  0.1061, -0.2896, -0.0624],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 4  contains  1964  embeddings.\n","Cluster 4 has centroid  tensor([ 0.0159, -0.0374,  0.0733, -0.0403,  0.0021,  0.0933, -0.3634, -0.0189],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 5  contains  2676  embeddings.\n","Cluster 5 has centroid  tensor([ 0.0333, -0.0538,  0.1410, -0.0339, -0.0154,  0.0194, -0.2185, -0.0790],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 6  contains  1071  embeddings.\n","Cluster 6 has centroid  tensor([ 0.0021, -0.0287,  0.1742, -0.0093, -0.0312,  0.0399, -0.2254, -0.0642],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 7  contains  2214  embeddings.\n","Cluster 7 has centroid  tensor([-0.0364, -0.0863,  0.1455, -0.0502, -0.0201,  0.0646, -0.3510, -0.0491],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 8  contains  2303  embeddings.\n","Cluster 8 has centroid  tensor([-0.0427, -0.0663,  0.1389,  0.0143,  0.0306, -0.0089, -0.2243, -0.0637],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 9  contains  2255  embeddings.\n","Cluster 9 has centroid  tensor([-0.0089, -0.0702,  0.1097,  0.0117, -0.0035,  0.0131, -0.3132, -0.0987],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 10  contains  2613  embeddings.\n","Cluster 10 has centroid  tensor([-0.0072, -0.0994,  0.0584,  0.0070, -0.0091,  0.0034, -0.3775, -0.0509],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 11  contains  2429  embeddings.\n","Cluster 11 has centroid  tensor([ 0.0249, -0.0170,  0.0747, -0.0206,  0.0399,  0.0184, -0.3712, -0.0031],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 12  contains  1572  embeddings.\n","Cluster 12 has centroid  tensor([-0.0287, -0.0382,  0.0831, -0.0150,  0.0138,  0.0729, -0.2211, -0.0446],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 13  contains  1379  embeddings.\n","Cluster 13 has centroid  tensor([-0.0122, -0.0295,  0.1381, -0.0265,  0.0117, -0.0019, -0.2479, -0.1199],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 14  contains  1713  embeddings.\n","Cluster 14 has centroid  tensor([ 0.0074, -0.1097,  0.1364, -0.0005,  0.0193,  0.0644, -0.3005, -0.0739],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 15  contains  1  embeddings.\n","Cluster 15 has centroid  tensor([-0.1131, -0.1622,  0.0466,  0.1138, -0.1768, -0.0983, -0.3593, -0.2961],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 16  contains  1679  embeddings.\n","Cluster 16 has centroid  tensor([-0.0560, -0.0582,  0.1022, -0.0388,  0.0279,  0.0387, -0.3387,  0.0092],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 17  contains  1122  embeddings.\n","Cluster 17 has centroid  tensor([ 0.0088, -0.0064,  0.1862, -0.0057, -0.0353,  0.0097, -0.2268, -0.0856],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 18  contains  3430  embeddings.\n","Cluster 18 has centroid  tensor([ 0.0097, -0.0342,  0.0918, -0.0091,  0.0039,  0.0167, -0.3064, -0.0513],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 19  contains  1556  embeddings.\n","Cluster 19 has centroid  tensor([-0.0302, -0.1071,  0.0921, -0.0120,  0.0352,  0.0251, -0.2308, -0.0436],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 20  contains  1  embeddings.\n","Cluster 20 has centroid  tensor([ 0.0856,  0.0583,  0.2540, -0.1384, -0.0357,  0.1387, -0.3901, -0.1160],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 21  contains  3028  embeddings.\n","Cluster 21 has centroid  tensor([ 0.0128, -0.0038,  0.0861, -0.0302,  0.0011,  0.0124, -0.3542, -0.0540],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 22  contains  3193  embeddings.\n","Cluster 22 has centroid  tensor([ 0.0060, -0.0658,  0.1873, -0.0160, -0.0236,  0.0266, -0.2273, -0.0531],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 23  contains  1984  embeddings.\n","Cluster 23 has centroid  tensor([ 0.0136, -0.0706,  0.1417, -0.0395,  0.0057,  0.0146, -0.2278, -0.0827],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Cluster 24  contains  2944  embeddings.\n","Cluster 24 has centroid  tensor([ 0.0091, -0.0927,  0.0833, -0.0402,  0.0043,  0.0550, -0.3687, -0.0594],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Smallest distance from centroid 0 to a token embedding in cluster 0 =  1.3089011907577515\n","The relevant token is  ['\\x07']\n","Its embedding starts  tensor([ 0.0293, -0.0453,  0.0911, -0.0343, -0.0457,  0.0537, -0.4484, -0.0734],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 0 : ['\\x07'] , vocab index 195\n","Distance from centroid 0 to this closest token = tensor(1.3089, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 1 to a token embedding in cluster 1 =  2.8027052879333496\n","The relevant token is  [' Batman']\n","Its embedding starts  tensor([-0.0163, -0.1774,  0.2027,  0.0346,  0.0490,  0.0035, -0.2254, -0.0087],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 1 : ['�'] , vocab index 187\n","Distance from centroid 1 to this closest token = tensor(1.6612, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 2 to a token embedding in cluster 2 =  2.518886089324951\n","The relevant token is  [' enhance']\n","Its embedding starts  tensor([ 0.0684, -0.0704,  0.0816,  0.0005, -0.1307,  0.0407, -0.4169, -0.1908],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 2 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 2 to this closest token = tensor(1.6429, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 3 to a token embedding in cluster 3 =  3.024597644805908\n","The relevant token is  [' Stacy']\n","Its embedding starts  tensor([-0.0020,  0.0153,  0.3106, -0.0859,  0.0774,  0.0790, -0.2274, -0.2170],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 3 : [' TheNitrome'] , vocab index 42089\n","Distance from centroid 3 to this closest token = tensor(2.2472, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 4 to a token embedding in cluster 4 =  2.3312599658966064\n","The relevant token is  [' gave']\n","Its embedding starts  tensor([ 0.0752, -0.0690,  0.1155, -0.0605, -0.0187, -0.0390, -0.3012, -0.1244],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 4 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 4 to this closest token = tensor(1.7876, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 5 to a token embedding in cluster 5 =  2.109713554382324\n","The relevant token is  ['Although']\n","Its embedding starts  tensor([ 0.0680, -0.0868,  0.0032, -0.0867, -0.0810,  0.0412, -0.2177, -0.0607],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 5 : ['�'] , vocab index 182\n","Distance from centroid 5 to this closest token = tensor(1.6453, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 6 to a token embedding in cluster 6 =  2.297480344772339\n","The relevant token is  [' Michael']\n","Its embedding starts  tensor([ 0.0274,  0.0232,  0.1719,  0.0401, -0.1076,  0.1000, -0.2232, -0.0395],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 6 : ['�'] , vocab index 182\n","Distance from centroid 6 to this closest token = tensor(1.8388, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 7 to a token embedding in cluster 7 =  2.9608941078186035\n","The relevant token is  ['becca']\n","Its embedding starts  tensor([ 0.0037,  0.0405,  0.1150, -0.0636, -0.0866, -0.0628, -0.3569, -0.1789],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 7 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 7 to this closest token = tensor(1.3583, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 8 to a token embedding in cluster 8 =  2.346113920211792\n","The relevant token is  [' FOR']\n","Its embedding starts  tensor([-0.0523, -0.0624,  0.1002, -0.0783,  0.0843,  0.0097, -0.2252, -0.0903],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 8 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 8 to this closest token = tensor(1.6764, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 9 to a token embedding in cluster 9 =  2.462104082107544\n","The relevant token is  ['that']\n","Its embedding starts  tensor([-0.0764, -0.0314,  0.1369,  0.0180,  0.0979,  0.0792, -0.2566, -0.1094],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 9 : ['\\x07'] , vocab index 195\n","Distance from centroid 9 to this closest token = tensor(1.6519, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 10 to a token embedding in cluster 10 =  2.2164034843444824\n","The relevant token is  [' putting']\n","Its embedding starts  tensor([-0.0040, -0.1069,  0.1199,  0.0080, -0.0326, -0.0665, -0.3374, -0.0078],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 10 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 10 to this closest token = tensor(1.7267, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 11 to a token embedding in cluster 11 =  2.1728944778442383\n","The relevant token is  [' extraordinarily']\n","Its embedding starts  tensor([ 0.0425, -0.0171,  0.0876, -0.0228,  0.1231,  0.0917, -0.3827,  0.0613],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 11 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 11 to this closest token = tensor(1.7112, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 12 to a token embedding in cluster 12 =  2.0032994747161865\n","The relevant token is  [' 284']\n","Its embedding starts  tensor([-0.0762, -0.0807, -0.0714, -0.1445,  0.1843,  0.2307, -0.2251, -0.1101],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 12 : ['�'] , vocab index 187\n","Distance from centroid 12 to this closest token = tensor(1.8527, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 13 to a token embedding in cluster 13 =  2.6532704830169678\n","The relevant token is  [' Germany']\n","Its embedding starts  tensor([-0.1314,  0.0461,  0.0410,  0.0766,  0.0929,  0.0313, -0.2241, -0.0053],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 13 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 13 to this closest token = tensor(1.7344, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 14 to a token embedding in cluster 14 =  2.927699089050293\n","The relevant token is  ['mmm']\n","Its embedding starts  tensor([ 0.0515, -0.0672,  0.2052, -0.0776,  0.0857,  0.0408, -0.3067, -0.1880],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 14 : ['\\x07'] , vocab index 195\n","Distance from centroid 14 to this closest token = tensor(1.7911, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 15 to a token embedding in cluster 15 =  0.0\n","The relevant token is  [' mixer']\n","Its embedding starts  tensor([-0.1131, -0.1622,  0.0466,  0.1138, -0.1768, -0.0983, -0.3593, -0.2961],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 15 : [' mixer'] , vocab index 33938\n","Distance from centroid 15 to this closest token = tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 16 to a token embedding in cluster 16 =  2.7718684673309326\n","The relevant token is  ['.,']\n","Its embedding starts  tensor([ 0.0409, -0.0784,  0.0758, -0.0721,  0.0634, -0.0664, -0.2442, -0.0560],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 16 : ['�'] , vocab index 179\n","Distance from centroid 16 to this closest token = tensor(1.8817, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 17 to a token embedding in cluster 17 =  2.832616090774536\n","The relevant token is  [' Clinton']\n","Its embedding starts  tensor([ 0.0564,  0.0451,  0.2792,  0.0545,  0.0004, -0.0496, -0.2250, -0.2172],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 17 : ['�'] , vocab index 187\n","Distance from centroid 17 to this closest token = tensor(1.7010, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 18 to a token embedding in cluster 18 =  2.085371255874634\n","The relevant token is  ['In']\n","Its embedding starts  tensor([-0.0097, -0.0819,  0.1068,  0.0415, -0.1234, -0.0438, -0.2173, -0.0972],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 18 : ['In'] , vocab index 818\n","Distance from centroid 18 to this closest token = tensor(2.0854, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 19 to a token embedding in cluster 19 =  1.8331282138824463\n","The relevant token is  ['�']\n","Its embedding starts  tensor([ 0.0219, -0.0798,  0.0359, -0.1168,  0.0725,  0.0477, -0.4648, -0.1235],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 19 : ['�'] , vocab index 187\n","Distance from centroid 19 to this closest token = tensor(1.5357, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 20 to a token embedding in cluster 20 =  0.0\n","The relevant token is  [' ware']\n","Its embedding starts  tensor([ 0.0856,  0.0583,  0.2540, -0.1384, -0.0357,  0.1387, -0.3901, -0.1160],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 20 : [' ware'] , vocab index 16202\n","Distance from centroid 20 to this closest token = tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 21 to a token embedding in cluster 21 =  2.5428466796875\n","The relevant token is  [' pushes']\n","Its embedding starts  tensor([-0.0734, -0.0338,  0.2159, -0.0893,  0.0602,  0.0277, -0.3422, -0.1976],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 21 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 21 to this closest token = tensor(1.8037, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 22 to a token embedding in cluster 22 =  2.214114189147949\n","The relevant token is  [' Although']\n","Its embedding starts  tensor([ 0.0286, -0.0567,  0.0194,  0.0210, -0.1217,  0.0107, -0.2242,  0.0091],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 22 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 22 to this closest token = tensor(1.7543, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 23 to a token embedding in cluster 23 =  2.7050769329071045\n","The relevant token is  [' Put']\n","Its embedding starts  tensor([ 0.0624, -0.1974,  0.1969, -0.0272,  0.0175, -0.0492, -0.2242,  0.0020],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 23 : ['�'] , vocab index 187\n","Distance from centroid 23 to this closest token = tensor(1.7928, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Smallest distance from centroid 24 to a token embedding in cluster 24 =  2.2357747554779053\n","The relevant token is  [' subur']\n","Its embedding starts  tensor([ 0.1556,  0.0174,  0.0724, -0.0010, -0.0182,  0.0823, -0.5290, -0.2198],\n","       device='cuda:0', grad_fn=<IndexBackward0>) ...\n","Closest token from entire vocab to centroid 24 : [' externalToEVA'] , vocab index 30212\n","Distance from centroid 24 to this closest token = tensor(1.5431, device='cuda:0', grad_fn=<NormBackward1>)\n","\n","\n","Distance from externalToEVA to centroids =  [1.3114159107208252, 1.6616042852401733, 1.6429270505905151, 2.255772829055786, 1.7876216173171997, 1.6464329957962036, 1.8411959409713745, 1.358313798904419, 1.6763665676116943, 1.6549421548843384, 1.726729393005371, 1.7112443447113037, 1.8585659265518188, 1.7344474792480469, 1.7916243076324463, 3.705548048019409, 1.883147120475769, 1.703123688697815, 2.349745988845825, 1.536261796951294, 3.98746657371521, 1.8036608695983887, 1.7543002367019653, 1.7974258661270142, 1.543114423751831]\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0271, -0.0444,  0.1192,  ...,  0.0087,  0.0022,  0.0960],\n","        [-0.0097, -0.0867,  0.2000,  ...,  0.0221,  0.0038,  0.0425],\n","        [ 0.0087, -0.0629,  0.1017,  ...,  0.0319, -0.0032,  0.0456],\n","        ...,\n","        [ 0.0060, -0.0658,  0.1873,  ...,  0.0349,  0.0032,  0.0447],\n","        [ 0.0136, -0.0706,  0.1417,  ...,  0.0286, -0.0112,  0.0104],\n","        [ 0.0091, -0.0927,  0.0833,  ...,  0.0421, -0.0138,  0.0427]],\n","       device='cuda:0', grad_fn=<StackBackward0>)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tev0cDbkdbxO"},"outputs":[],"source":["ix = tokenizer.encode(\"\")\n","# list of 'vocab indices'\n","print(ix)\n","print([tokenizer.decode(i) for i in ix])\n","# prints reconstruction of input string\n","print(len(ix))\n","# prints number of tokens\n","output_len=2\n","model_out = model.generate(torch.tensor(ix).unsqueeze(0).to(device), max_length = output_len + len(ix))\n","print(tokenizer.decode(model_out[0]))\n","# pushes input string throught GPT2 (or whichever model) iteratively producing output_len number of tokens, then prints input + output."]},{"cell_type":"code","source":["from time import time\n","target_output = \" a lot of data.\"\n","input_len = 3\n","\n","tic = time()\n","oi = optimise_input(base_input=True, \n","                    plt_loss=False,\n","                    verbose=2, \n","                    epochs=500, \n","                    lr_decay=False,\n","                    return_early=False, \n","                    lr=0.1, \n","                    batch_size=20, \n","                    target_output=target_output, \n","                    output_len=4,\n","                    input_len=input_len, \n","                    w_freq=20, \n","                    dist_reg=1, \n","                    perp_reg=0,\n","                    loss_type='log_prob_loss',\n","                    noise_coeff = 0.75)\n","toc = time()\n","tt = toc - tic\n","print('Time Taken: ', tt)"],"metadata":{"id":"FV8hwEsWcDgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Nk_-t5j3hdGc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["experiments = [{'base_input': True, \n","                'plt_loss': False, \n","                'verbose': 1, \n","                'epochs': 1000, \n","                'lr_decay': False, \n","                'return_early': False, \n","                'lr': 0.1, \n","                'batch_size': 50, \n","                'target_output': ' a lot of data', \n","                'output_len': 4, \n","                'input_len': 3, \n","                'w_freq': 20, \n","                'dist_reg': 1, \n","                'perp_reg': 0, \n","                'loss_type': 'log_prob_loss',\n","                'note':''}\n","                ]\n","\n","\n","experiment_log = {}"],"metadata":{"id":"y8NBHj-uOnDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for e in experiments:\n","    tick = time()\n","    results = optimise_input(**e)\n","    tock = time()\n","    rt = tock - tick\n","    results.update({'runtime':rt})\n","    \n","    with open(\"backwards_results.json\",\"a\") as f:\n","        f.write(json.dumps({tick:results}))\n"],"metadata":{"id":"81r4gT4m2NQ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This runs 500 batches of 50 and keeps track of the most common closest tokens to centroid embeddings, and how many appeareances they make\n","token_counts = torch.zeros(vocab_len)\n","for j in range(500):\n","    print('batch', j)\n","    centroids = kmeans(50)\n","    for i in range(50):\n","        token_counts[closest_tokens(centroids[i])[1].item()] +=1\n","\n","values, indices = torch.sort(token_counts, descending=True)\n","print(indices[:50], values[:50])"],"metadata":{"id":"442OukV-eUID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["most_common_tokens_idxs = [30212,   187,   195,   216,   182,   179,   213, 39820,   199,   124,\n","          208,   125, 23090,   554, 30208,   281,  3607,  7003,   192, 37528,\n","        15524,   217, 39752, 42089,   183,   818,   210,   201,   209,   207,\n","          211,   206,  1026,   189,   190,  1315,   219,   205,   212,   203,\n","          287,   188, 30898, 45544, 14827,   218, 30897,   202,   181, 30905]\n","most_common_tokens = [tokenizer.decode(i) for i in most_common_tokens_idxs]\n","print(most_common_tokens)\n","print(word_embeddings[30212])"],"metadata":{"id":"WI9LivBAofa2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kmeans(50)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Lx2HxfIhi4B","executionInfo":{"status":"ok","timestamp":1673452548528,"user_tz":0,"elapsed":2215,"user":{"displayName":"The Inamorata Press","userId":"11358823481707850507"}},"outputId":"811f7972-db4d-4e3e-8083-e1e3143b9d29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["iteration:  1 \n"," max distance between old and new centroids: 9.975008010864258\n","iteration:  2 \n"," max distance between old and new centroids: 1.3475738763809204\n","iteration:  3 \n"," max distance between old and new centroids: 1.0740748643875122\n","iteration:  4 \n"," max distance between old and new centroids: 0.8603959679603577\n","iteration:  5 \n"," max distance between old and new centroids: 0.9484898447990417\n","iteration:  6 \n"," max distance between old and new centroids: 0.6111389994621277\n","iteration:  7 \n"," max distance between old and new centroids: 0.33316004276275635\n","iteration:  8 \n"," max distance between old and new centroids: 0.25298264622688293\n","iteration:  9 \n"," max distance between old and new centroids: 0.1368548721075058\n","iteration:  10 \n"," max distance between old and new centroids: 0.1660463809967041\n","iteration:  11 \n"," max distance between old and new centroids: 0.18448098003864288\n","iteration:  12 \n"," max distance between old and new centroids: 0.3939077854156494\n","iteration:  13 \n"," max distance between old and new centroids: 0.31010088324546814\n","iteration:  14 \n"," max distance between old and new centroids: 0.2966088652610779\n","iteration:  15 \n"," max distance between old and new centroids: 0.32974058389663696\n","iteration:  16 \n"," max distance between old and new centroids: 0.28324905037879944\n","iteration:  17 \n"," max distance between old and new centroids: 0.21531817317008972\n","iteration:  18 \n"," max distance between old and new centroids: 0.1647544950246811\n","iteration:  19 \n"," max distance between old and new centroids: 0.16203825175762177\n","iteration:  20 \n"," max distance between old and new centroids: 0.18794181942939758\n","iteration:  21 \n"," max distance between old and new centroids: 0.11542848497629166\n","iteration:  22 \n"," max distance between old and new centroids: 0.1134076714515686\n","iteration:  23 \n"," max distance between old and new centroids: 0.08779381960630417\n","iteration:  24 \n"," max distance between old and new centroids: 0.06194668635725975\n","iteration:  25 \n"," max distance between old and new centroids: 0.05671731382608414\n","iteration:  26 \n"," max distance between old and new centroids: 0.06488916277885437\n","iteration:  27 \n"," max distance between old and new centroids: 0.07173579186201096\n","iteration:  28 \n"," max distance between old and new centroids: 0.087642602622509\n","iteration:  29 \n"," max distance between old and new centroids: 0.09307590872049332\n","iteration:  30 \n"," max distance between old and new centroids: 0.08441592752933502\n","iteration:  31 \n"," max distance between old and new centroids: 0.08475013077259064\n","iteration:  32 \n"," max distance between old and new centroids: 0.06981449574232101\n","iteration:  33 \n"," max distance between old and new centroids: 0.047706130892038345\n","iteration:  34 \n"," max distance between old and new centroids: 0.0323902927339077\n","iteration:  35 \n"," max distance between old and new centroids: 0.02163095213472843\n","iteration:  36 \n"," max distance between old and new centroids: 0.014823979698121548\n","iteration:  37 \n"," max distance between old and new centroids: 0.01180209405720234\n","iteration:  38 \n"," max distance between old and new centroids: 0.01028451044112444\n","iteration:  39 \n"," max distance between old and new centroids: 0.009991345927119255\n","Cluster 0  contains  1235  embeddings.\n","Cluster 1  contains  1831  embeddings.\n","Cluster 2  contains  902  embeddings.\n","Cluster 3  contains  736  embeddings.\n","Cluster 4  contains  1133  embeddings.\n","Cluster 5  contains  1502  embeddings.\n","Cluster 6  contains  2031  embeddings.\n","Cluster 7  contains  8  embeddings.\n","Cluster 8  contains  674  embeddings.\n","Cluster 9  contains  1345  embeddings.\n","Cluster 10  contains  2046  embeddings.\n","Cluster 11  contains  1250  embeddings.\n","Cluster 12  contains  5  embeddings.\n","Cluster 13  contains  730  embeddings.\n","Cluster 14  contains  2528  embeddings.\n","Cluster 15  contains  884  embeddings.\n","Cluster 16  contains  1785  embeddings.\n","Cluster 17  contains  963  embeddings.\n","Cluster 18  contains  2170  embeddings.\n","Cluster 19  contains  625  embeddings.\n","Cluster 20  contains  1270  embeddings.\n","Cluster 21  contains  1049  embeddings.\n","Cluster 22  contains  1499  embeddings.\n","Cluster 23  contains  922  embeddings.\n","Cluster 24  contains  3  embeddings.\n","Cluster 25  contains  1076  embeddings.\n","Cluster 26  contains  1628  embeddings.\n","Cluster 27  contains  691  embeddings.\n","Cluster 28  contains  1090  embeddings.\n","Cluster 29  contains  590  embeddings.\n","Cluster 30  contains  18  embeddings.\n","Cluster 31  contains  1004  embeddings.\n","Cluster 32  contains  1339  embeddings.\n","Cluster 33  contains  1110  embeddings.\n","Cluster 34  contains  655  embeddings.\n","Cluster 35  contains  1565  embeddings.\n","Cluster 36  contains  1137  embeddings.\n","Cluster 37  contains  3  embeddings.\n","Cluster 38  contains  563  embeddings.\n","Cluster 39  contains  1  embeddings.\n","Cluster 40  contains  1040  embeddings.\n","Cluster 41  contains  1379  embeddings.\n","Cluster 42  contains  568  embeddings.\n","Cluster 43  contains  1214  embeddings.\n","Cluster 44  contains  5  embeddings.\n","Cluster 45  contains  1116  embeddings.\n","Cluster 46  contains  605  embeddings.\n","Cluster 47  contains  16  embeddings.\n","Cluster 48  contains  1233  embeddings.\n","Cluster 49  contains  1485  embeddings.\n","Closest token to centroid  0 :  ['�'] 187\n","Closest token to centroid  1 :  ['\\x07'] 195\n","Closest token to centroid  2 :  [' externalToEVA'] 30212\n","Closest token to centroid  3 :  ['\\x14'] 208\n","Closest token to centroid  4 :  [' externalToEVA'] 30212\n","Closest token to centroid  5 :  ['\\x07'] 195\n","Closest token to centroid  6 :  ['\\x1c'] 216\n","Closest token to centroid  7 :  ['�'] 124\n","Closest token to centroid  8 :  [' 258'] 37528\n","Closest token to centroid  9 :  ['\\x1c'] 216\n","Closest token to centroid  10 :  [' externalToEVA'] 30212\n","Closest token to centroid  11 :  ['�'] 187\n","Closest token to centroid  12 :  ['\\x16'] 210\n","Closest token to centroid  13 :  ['\\x1c'] 216\n","Closest token to centroid  14 :  [' externalToEVA'] 30212\n","Closest token to centroid  15 :  [' externalToEVA'] 30212\n","Closest token to centroid  16 :  [' externalToEVA'] 30212\n","Closest token to centroid  17 :  ['�'] 187\n","Closest token to centroid  18 :  ['�'] 182\n","Closest token to centroid  19 :  ['�'] 179\n","Closest token to centroid  20 :  ['�'] 182\n","Closest token to centroid  21 :  [' externalToEVA'] 30212\n","Closest token to centroid  22 :  [' externalToEVA'] 30212\n","Closest token to centroid  23 :  [' externalToEVA'] 30212\n","Closest token to centroid  24 :  ['\\x13'] 207\n","Closest token to centroid  25 :  [' externalToEVA'] 30212\n","Closest token to centroid  26 :  [' externalTo'] 30208\n","Closest token to centroid  27 :  ['Although'] 7003\n","Closest token to centroid  28 :  ['龍�'] 39820\n","Closest token to centroid  29 :  ['\\x07'] 195\n","Closest token to centroid  30 :  ['\\x1c'] 216\n","Closest token to centroid  31 :  ['�'] 187\n","Closest token to centroid  32 :  [' an'] 281\n","Closest token to centroid  33 :  ['�'] 187\n","Closest token to centroid  34 :  [' externalToEVA'] 30212\n","Closest token to centroid  35 :  ['�'] 179\n","Closest token to centroid  36 :  ['\\x19'] 213\n","Closest token to centroid  37 :  ['opia'] 24464\n","Closest token to centroid  38 :  [' externalToEVA'] 30212\n","Closest token to centroid  39 :  ['SPONSORED'] 37190\n","Closest token to centroid  40 :  ['�'] 182\n","Closest token to centroid  41 :  ['�'] 187\n","Closest token to centroid  42 :  [' externalToEVA'] 30212\n","Closest token to centroid  43 :  [' externalToEVA'] 30212\n","Closest token to centroid  44 :  ['opathic'] 44650\n","Closest token to centroid  45 :  [' externalToEVA'] 30212\n","Closest token to centroid  46 :  [' externalToEVA'] 30212\n","Closest token to centroid  47 :  [' source'] 2723\n","Closest token to centroid  48 :  ['�'] 187\n","Closest token to centroid  49 :  [' externalToEVA'] 30212\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0104, -0.0040,  0.1911,  ...,  0.0722,  0.0364,  0.0326],\n","        [-0.0345, -0.0401,  0.1126,  ..., -0.0033,  0.0024,  0.0945],\n","        [ 0.0398, -0.0695,  0.1101,  ...,  0.0185,  0.0169,  0.0675],\n","        ...,\n","        [-0.0405, -0.0464,  0.1556,  ..., -0.0407, -0.0773,  0.1004],\n","        [ 0.0124, -0.0839,  0.1270,  ...,  0.0342,  0.0066,  0.0149],\n","        [ 0.0070, -0.0486,  0.0823,  ...,  0.0153, -0.0139,  0.0207]],\n","       device='cuda:0', grad_fn=<StackBackward0>)"]},"metadata":{},"execution_count":27}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"https://github.com/jessicamarycooper/Backwards/blob/main/Backwards.ipynb","timestamp":1673283314661}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e61a7c095aac47f18bde8251f34b5ac1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5df399ed727049629c02310784a07739","IPY_MODEL_6d3d47869b15430a8b4d294584890e0d","IPY_MODEL_d35425dc791e427d81508b9e830b25ec"],"layout":"IPY_MODEL_901af3867e1f4cc59fa95eab87e5c0f0"}},"5df399ed727049629c02310784a07739":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4dc593fb4264268b439605c40d5f1d1","placeholder":"​","style":"IPY_MODEL_b892cbd7adf544ab81717dc22710e3ba","value":"Downloading: 100%"}},"6d3d47869b15430a8b4d294584890e0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_428301bbbd5e413ea281151257b4c664","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e6e6da84d6d4dbd890a34b320b9480f","value":1042301}},"d35425dc791e427d81508b9e830b25ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dcb3e193f084912b35fe9371fad77af","placeholder":"​","style":"IPY_MODEL_c90ad7ab7c0f47ea981da857d5ebeb6a","value":" 1.04M/1.04M [00:00&lt;00:00, 1.57MB/s]"}},"901af3867e1f4cc59fa95eab87e5c0f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4dc593fb4264268b439605c40d5f1d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b892cbd7adf544ab81717dc22710e3ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"428301bbbd5e413ea281151257b4c664":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e6e6da84d6d4dbd890a34b320b9480f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5dcb3e193f084912b35fe9371fad77af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c90ad7ab7c0f47ea981da857d5ebeb6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"732a5b2d5f11421290b4ab2821012637":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d61fb9738fb343528fd045de685fa0cf","IPY_MODEL_ac191566050f4defabd27612949e70da","IPY_MODEL_20045e7342654adb8542c53191d566a1"],"layout":"IPY_MODEL_fddb87edd610475a853bf74f3e50071e"}},"d61fb9738fb343528fd045de685fa0cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec5b70bf6a2f44d1aab44ee73129639c","placeholder":"​","style":"IPY_MODEL_11cf330f84bb442fbecec383b62cd3a0","value":"Downloading: 100%"}},"ac191566050f4defabd27612949e70da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6065acb9bbe14f02ba18e7eca039e5f3","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c978f86dc5a491188d4b0002292ec7e","value":456318}},"20045e7342654adb8542c53191d566a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50fa07c7990b477299ad7522e1d69c42","placeholder":"​","style":"IPY_MODEL_88f098ee31d948dba9f0081b3b99d462","value":" 456k/456k [00:00&lt;00:00, 1.81MB/s]"}},"fddb87edd610475a853bf74f3e50071e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec5b70bf6a2f44d1aab44ee73129639c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11cf330f84bb442fbecec383b62cd3a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6065acb9bbe14f02ba18e7eca039e5f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c978f86dc5a491188d4b0002292ec7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50fa07c7990b477299ad7522e1d69c42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88f098ee31d948dba9f0081b3b99d462":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87ab70f75ed34237af93fd0061fefd12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_888455fec6bf4c8ea09f411d4cba699f","IPY_MODEL_93ee355564e94696bbb32ac09e49f69a","IPY_MODEL_4d5209794d24493ea55ce4660817418b"],"layout":"IPY_MODEL_1ad2c8dc57ca4fbb99698e0970fc9359"}},"888455fec6bf4c8ea09f411d4cba699f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13fd2719c48c4be7bdcc4268838e023d","placeholder":"​","style":"IPY_MODEL_40f0321e38a240d8bf9cb806fb644e8c","value":"Downloading: 100%"}},"93ee355564e94696bbb32ac09e49f69a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa055ee6d2d4fc5ab9098ef994a6470","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74962eb3fe7b4781b18c58fd24122330","value":665}},"4d5209794d24493ea55ce4660817418b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01d66415c0674f708e1ad170bc72bfaf","placeholder":"​","style":"IPY_MODEL_0db040840ed44757b37ebc8b0dead8fd","value":" 665/665 [00:00&lt;00:00, 55.2kB/s]"}},"1ad2c8dc57ca4fbb99698e0970fc9359":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13fd2719c48c4be7bdcc4268838e023d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40f0321e38a240d8bf9cb806fb644e8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aa055ee6d2d4fc5ab9098ef994a6470":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74962eb3fe7b4781b18c58fd24122330":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01d66415c0674f708e1ad170bc72bfaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db040840ed44757b37ebc8b0dead8fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7925e231a35a4b96b87d601c1ebe7c1f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93935b4706024fcea44fa9d960053043","IPY_MODEL_e1888e0200314b7a851030143b432690","IPY_MODEL_0ec3120478284fc9b0ba17f925ca6fda"],"layout":"IPY_MODEL_d7b10343c5c5408499a2ca78414c916e"}},"93935b4706024fcea44fa9d960053043":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e32c3fd4d0e943d59d9c13d72a773264","placeholder":"​","style":"IPY_MODEL_3ae03af8fb694489b15bdef17246d6c0","value":"Downloading: 100%"}},"e1888e0200314b7a851030143b432690":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e89cf8e8508f4810b4df82db58061d46","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb6837190d0241a9a0544a23250d1b81","value":548118077}},"0ec3120478284fc9b0ba17f925ca6fda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb3717f17b694502882607be5d56f5b7","placeholder":"​","style":"IPY_MODEL_7338745f7720483caf4bb5e76bb9a97e","value":" 548M/548M [00:07&lt;00:00, 75.3MB/s]"}},"d7b10343c5c5408499a2ca78414c916e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e32c3fd4d0e943d59d9c13d72a773264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ae03af8fb694489b15bdef17246d6c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e89cf8e8508f4810b4df82db58061d46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb6837190d0241a9a0544a23250d1b81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb3717f17b694502882607be5d56f5b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7338745f7720483caf4bb5e76bb9a97e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}